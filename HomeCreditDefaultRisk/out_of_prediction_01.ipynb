{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    \n",
    "    prev_dtype = {\n",
    "        'SK_ID_PREV': np.uint32, 'SK_ID_CURR': np.uint32, 'HOUR_APPR_PROCESS_START': np.int32, 'NFLAG_LAST_APPL_IN_DAY': np.int32,\n",
    "        'DAYS_DECISION': np.int32, 'SELLERPLACE_AREA': np.int32, 'AMT_ANNUITY': np.float32, 'AMT_APPLICATION': np.float32,\n",
    "        'AMT_CREDIT': np.float32, 'AMT_DOWN_PAYMENT': np.float32, 'AMT_GOODS_PRICE': np.float32, 'RATE_DOWN_PAYMENT': np.float32,\n",
    "        'RATE_INTEREST_PRIMARY': np.float32, 'RATE_INTEREST_PRIVILEGED': np.float32, 'CNT_PAYMENT': np.float32,\n",
    "        'DAYS_FIRST_DRAWING': np.float32, 'DAYS_FIRST_DUE': np.float32, 'DAYS_LAST_DUE_1ST_VERSION': np.float32,\n",
    "        'DAYS_LAST_DUE': np.float32, 'DAYS_TERMINATION': np.float32, 'NFLAG_INSURED_ON_APPROVAL': np.float32\n",
    "    }\n",
    "    \n",
    "    bureau_dtype = {\n",
    "        'SK_ID_CURR': np.uint32, 'SK_ID_BUREAU': np.uint32, 'DAYS_CREDIT': np.int32,'CREDIT_DAY_OVERDUE': np.int32,\n",
    "        'CNT_CREDIT_PROLONG': np.int32, 'DAYS_CREDIT_UPDATE': np.int32, 'DAYS_CREDIT_ENDDATE': np.float32,\n",
    "        'DAYS_ENDDATE_FACT': np.float32, 'AMT_CREDIT_MAX_OVERDUE': np.float32, 'AMT_CREDIT_SUM': np.float32,\n",
    "        'AMT_CREDIT_SUM_DEBT': np.float32, 'AMT_CREDIT_SUM_LIMIT': np.float32, 'AMT_CREDIT_SUM_OVERDUE': np.float32,\n",
    "        'AMT_ANNUITY': np.float32\n",
    "    }\n",
    "    \n",
    "    bureau_bal_dtype = {\n",
    "        'SK_ID_BUREAU': np.int32, 'MONTHS_BALANCE': np.int32,\n",
    "    }\n",
    "    \n",
    "    pos_dtype = {\n",
    "        'SK_ID_PREV': np.uint32, 'SK_ID_CURR': np.uint32, 'MONTHS_BALANCE': np.int32, 'SK_DPD': np.int32,\n",
    "        'SK_DPD_DEF': np.int32, 'CNT_INSTALMENT': np.float32,'CNT_INSTALMENT_FUTURE': np.float32,\n",
    "    }\n",
    "    \n",
    "    install_dtype = {\n",
    "        'SK_ID_PREV': np.uint32, 'SK_ID_CURR': np.uint32, 'NUM_INSTALMENT_NUMBER': np.int32, 'NUM_INSTALMENT_VERSION': np.float32,\n",
    "        'DAYS_INSTALMENT': np.float32, 'DAYS_ENTRY_PAYMENT': np.float32, 'AMT_INSTALMENT': np.float32, 'AMT_PAYMENT': np.float32,\n",
    "    }\n",
    "    \n",
    "    card_dtype = {\n",
    "        'SK_ID_PREV': np.uint32, 'SK_ID_CURR': np.uint32, 'MONTHS_BALANCE': np.int16,\n",
    "        'AMT_CREDIT_LIMIT_ACTUAL': np.int32, 'CNT_DRAWINGS_CURRENT': np.int32, 'SK_DPD': np.int32,'SK_DPD_DEF': np.int32,\n",
    "        'AMT_BALANCE': np.float32, 'AMT_DRAWINGS_ATM_CURRENT': np.float32, 'AMT_DRAWINGS_CURRENT': np.float32,\n",
    "        'AMT_DRAWINGS_OTHER_CURRENT': np.float32, 'AMT_DRAWINGS_POS_CURRENT': np.float32, 'AMT_INST_MIN_REGULARITY': np.float32,\n",
    "        'AMT_PAYMENT_CURRENT': np.float32, 'AMT_PAYMENT_TOTAL_CURRENT': np.float32, 'AMT_RECEIVABLE_PRINCIPAL': np.float32,\n",
    "        'AMT_RECIVABLE': np.float32, 'AMT_TOTAL_RECEIVABLE': np.float32, 'CNT_DRAWINGS_ATM_CURRENT': np.float32,\n",
    "        'CNT_DRAWINGS_OTHER_CURRENT': np.float32, 'CNT_DRAWINGS_POS_CURRENT': np.float32, 'CNT_INSTALMENT_MATURE_CUM': np.float32,\n",
    "    }\n",
    "    \n",
    "    app_train = pd.read_csv('../data/home-credit-default-risk/application_train.csv')\n",
    "    app_test = pd.read_csv('../data/home-credit-default-risk/application_test.csv')\n",
    "    apps = pd.concat([app_train, app_test])\n",
    "    prev = pd.read_csv('../data/home-credit-default-risk/previous_application.csv', dtype=prev_dtype)\n",
    "    bureau = pd.read_csv('../data/home-credit-default-risk/bureau.csv', dtype=bureau_dtype)\n",
    "    bureau_balance = pd.read_csv('../data/home-credit-default-risk/bureau_balance.csv', dtype=bureau_bal_dtype)\n",
    "    pos_bal = pd.read_csv('../data/home-credit-default-risk/POS_CASH_balance.csv', dtype=pos_dtype)\n",
    "    install = pd.read_csv('../data/home-credit-default-risk/installments_payments.csv', dtype=install_dtype)\n",
    "    card_bal = pd.read_csv('../data/home-credit-default-risk/credit_card_balance.csv', dtype=card_dtype)\n",
    "    \n",
    "    return apps, prev, bureau, bureau_balance, pos_bal, install, card_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "def get_apps_processed(apps):\n",
    "    apps['APPS_EXT_SOURCE_MEAN'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "    apps['APPS_EXT_SOURCE_STD'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "    apps['APPS_EXT_SOURCE_STD'] = apps['APPS_EXT_SOURCE_STD'].fillna(apps['APPS_EXT_SOURCE_STD'].mean())\n",
    "    \n",
    "    apps['APPS_ANNUITY_CREDIT_RATIO'] = apps['AMT_ANNUITY'] / apps['AMT_CREDIT']\n",
    "    apps['APPS_GOODS_CREDIT_RATIO'] = apps['AMT_GOODS_PRICE'] / apps['AMT_CREDIT']\n",
    "    apps['APPS_CREDIT_GOODS_DIFF'] = apps['AMT_CREDIT'] - apps['AMT_GOODS_PRICE']\n",
    "    \n",
    "    apps['APPS_ANNUITY_INCOME_RATIO'] = apps['AMT_ANNUITY'] / apps['AMT_INCOME_TOTAL']\n",
    "    apps['APPS_CREDIT_INCOME_RATIO'] = apps['AMT_CREDIT'] / apps['AMT_INCOME_TOTAL']\n",
    "    apps['APPS_GOODS_INCOME_RATIO'] = apps['AMT_GOODS_PRICE'] / apps['AMT_INCOME_TOTAL']\n",
    "    apps['APPS_CNT_FAM_INCOME_RATIO'] = apps['AMT_INCOME_TOTAL'] / apps['CNT_FAM_MEMBERS']\n",
    "    \n",
    "    apps['APPS_EMPLOYED_BIRTH_RATIO'] = apps['DAYS_EMPLOYED'] / apps['DAYS_BIRTH']\n",
    "    apps['APPS_INCOME_EMPLOYED_RATIO'] = apps['AMT_INCOME_TOTAL'] / apps['DAYS_EMPLOYED']\n",
    "    apps['APPS_INCOME_BIRTH_RATIO'] = apps['AMT_INCOME_TOTAL'] / apps['DAYS_BIRTH']\n",
    "    apps['APPS_CAR_BIRTH_RATIO'] = apps['OWN_CAR_AGE'] / apps['DAYS_BIRTH']\n",
    "    apps['APPS_CAR_EMPLOYED_RATIO'] = apps['OWN_CAR_AGE'] / apps['DAYS_EMPLOYED']\n",
    "    \n",
    "    return apps\n",
    "\n",
    "\n",
    "def get_prev_processed(prev):\n",
    "    \n",
    "    prev['PREV_CREDIT_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\n",
    "    prev['PREV_GOODS_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_GOODS_PRICE']\n",
    "    prev['PREV_CREDIT_APPL_RATIO'] = prev['AMT_CREDIT'] / prev['AMT_APPLICATION']\n",
    "    prev['PREV_ANNUITY_APPL_RATIO'] = prev['AMT_ANNUITY'] / prev['AMT_APPLICATION']\n",
    "    prev['PREV_GOODS_APPL_RATIO'] = prev['AMT_GOODS_PRICE'] / prev['AMT_APPLICATION']\n",
    "    \n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "    prev['PREV_DAYS_LAST_DUE_DIFF'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n",
    "    \n",
    "    all_pay = prev['AMT_ANNUITY'] * prev['CNT_PAYMENT']\n",
    "    prev['PREV_INTERESTS_RATE'] = (all_pay / prev['AMT_CREDIT'] - 1) / prev['CNT_PAYMENT']\n",
    "    \n",
    "    return prev\n",
    "\n",
    "\n",
    "def get_prev_amt_agg(prev):    \n",
    "\n",
    "    agg_dict = {\n",
    "         # 기존 컬럼. \n",
    "        'SK_ID_CURR':['count'],\n",
    "        'AMT_CREDIT':['mean', 'max', 'sum'],\n",
    "        'AMT_ANNUITY':['mean', 'max', 'sum'], \n",
    "        'AMT_APPLICATION':['mean', 'max', 'sum'],\n",
    "        'AMT_DOWN_PAYMENT':['mean', 'max', 'sum'],\n",
    "        'AMT_GOODS_PRICE':['mean', 'max', 'sum'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "        # 가공 컬럼\n",
    "        'PREV_CREDIT_DIFF':['mean', 'max', 'sum'], \n",
    "        'PREV_CREDIT_APPL_RATIO':['mean', 'max'],\n",
    "        'PREV_GOODS_DIFF':['mean', 'max', 'sum'],\n",
    "        'PREV_GOODS_APPL_RATIO':['mean', 'max'],\n",
    "        'PREV_DAYS_LAST_DUE_DIFF':['mean', 'max', 'sum'],\n",
    "        'PREV_INTERESTS_RATE':['mean', 'max']\n",
    "    }\n",
    "    \n",
    "    prev_group = prev.groupby('SK_ID_CURR')\n",
    "    prev_amt_agg = prev_group.agg(agg_dict)\n",
    "    prev_amt_agg.columns = ['PREV_' + ('_').join(column).upper() for column in prev_amt_agg.columns.ravel()]\n",
    "    prev_amt_agg = prev_amt_agg.reset_index()\n",
    "    \n",
    "    return prev_amt_agg\n",
    "\n",
    "\n",
    "def get_prev_refused_appr_agg(prev):\n",
    "\n",
    "    prev_refused_appr_group = prev[prev['NAME_CONTRACT_STATUS'].isin(['Approved', 'Refused'])].groupby(['SK_ID_CURR', 'NAME_CONTRACT_STATUS'])\n",
    "    prev_refused_appr_agg = prev_refused_appr_group['SK_ID_CURR'].count().unstack()\n",
    "    prev_refused_appr_agg = prev_refused_appr_agg.fillna(0)\n",
    "    prev_refused_appr_agg.columns = ['PREV_APPROVED_COUNT', 'PREV_REFUSED_COUNT']\n",
    "    prev_refused_appr_agg = prev_refused_appr_agg.reset_index()\n",
    "    \n",
    "    return prev_refused_appr_agg\n",
    "\n",
    "\n",
    "def get_prev_agg(prev):\n",
    "    \n",
    "    prev = get_prev_processed(prev)\n",
    "    prev_amt_agg = get_prev_amt_agg(prev)\n",
    "    prev_refused_appr_agg = get_prev_refused_appr_agg(prev)\n",
    "    \n",
    "    prev_agg = prev_amt_agg.merge(prev_refused_appr_agg, on='SK_ID_CURR', how='left')\n",
    "    prev_agg['PREV_REFUSED_RATIO'] = prev_agg['PREV_REFUSED_COUNT'] / prev_agg['PREV_SK_ID_CURR_COUNT']\n",
    "    prev_agg['PREV_APPROVED_RATIO'] = prev_agg['PREV_APPROVED_COUNT'] / prev_agg['PREV_SK_ID_CURR_COUNT']\n",
    "    prev_agg = prev_agg.drop(['PREV_REFUSED_COUNT', 'PREV_APPROVED_COUNT'], axis=1)\n",
    "    \n",
    "    return prev_agg\n",
    "\n",
    "\n",
    "def get_apps_all_with_prev_agg(apps, prev):\n",
    "\n",
    "    apps_all = get_apps_processed(apps)\n",
    "    prev_agg = get_prev_agg(prev)\n",
    "    print('prev_agg shape:', prev_agg.shape)\n",
    "    print('apps_all before merge shape:', apps_all.shape)\n",
    "    apps_all = apps_all.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
    "    print('apps_all after merge with prev_agg shape:', apps_all.shape)\n",
    "    \n",
    "    return apps_all\n",
    "\n",
    "\n",
    "def get_apps_all_encoded(apps_all):\n",
    "    \n",
    "    object_columns = apps_all.dtypes[apps_all.dtypes == 'object'].index.tolist()\n",
    "    for column in object_columns:\n",
    "        apps_all[column] = pd.factorize(apps_all[column])[0]\n",
    "    \n",
    "    return apps_all\n",
    "\n",
    "\n",
    "def get_apps_all_train_test(apps_all):\n",
    "\n",
    "    apps_all_train = apps_all[~apps_all['TARGET'].isnull()]\n",
    "    apps_all_test = apps_all[apps_all['TARGET'].isnull()]\n",
    "    apps_all_test = apps_all_test.drop('TARGET', axis=1)\n",
    "    \n",
    "    return apps_all_train, apps_all_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_agg_dict = {\n",
    "    'SK_ID_BUREAU': ['count'],\n",
    "    'DAYS_CREDIT': ['min', 'max', 'mean'],\n",
    "    'CREDIT_DAY_OVERDUE': ['min', 'max', 'mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "    'DAYS_ENDDATE_FACT': ['min', 'max', 'mean'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n",
    "    'AMT_ANNUITY': ['max', 'mean', 'sum'],\n",
    "\n",
    "    'BUREAU_ENDDATE_FACT_DIFF': ['min', 'max', 'mean'],\n",
    "    'BUREAU_CREDIT_FACT_DIFF': ['min', 'max', 'mean'],\n",
    "    'BUREAU_CREDIT_ENDDATE_DIFF': ['min', 'max', 'mean'],\n",
    "    'BUREAU_CREDIT_DEBT_RATIO': ['min', 'max', 'mean'],\n",
    "    'BUREAU_CREDIT_DEBT_DIFF': ['min', 'max', 'mean'],\n",
    "    'BUREAU_IS_DPD': ['mean', 'sum'],\n",
    "    'BUREAU_IS_DPD_OVER120': ['mean', 'sum'],\n",
    "}\n",
    "\n",
    "bureau_bal_agg_dict = {\n",
    "    'SK_ID_CURR': ['count'],\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'mean'],\n",
    "    'BUREAU_BAL_IS_DPD': ['mean', 'sum'],\n",
    "    'BUREAU_BAL_IS_DPD_OVER120': ['mean', 'sum'],\n",
    "}\n",
    "\n",
    "def get_bureau_processed(bureau):\n",
    "    \n",
    "    bureau['BUREAU_ENDDATE_FACT_DIFF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n",
    "    bureau['BUREAU_CREDIT_FACT_DIFF'] = bureau['DAYS_CREDIT'] - bureau['DAYS_ENDDATE_FACT']\n",
    "    bureau['BUREAU_CREDIT_ENDDATE_DIFF'] = bureau['DAYS_CREDIT'] - bureau['DAYS_CREDIT_ENDDATE']\n",
    "\n",
    "    bureau['BUREAU_CREDIT_DEBT_RATIO'] = bureau['AMT_CREDIT_SUM_DEBT'] / bureau['AMT_CREDIT_SUM']\n",
    "    bureau['BUREAU_CREDIT_DEBT_DIFF'] = bureau['AMT_CREDIT_SUM_DEBT'] - bureau['AMT_CREDIT_SUM']\\\n",
    "    \n",
    "    bureau['BUREAU_IS_DPD'] = bureau['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    bureau['BUREAU_IS_DPD_OVER120'] = bureau['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x > 120 else 0)\n",
    "    \n",
    "    return bureau\n",
    "\n",
    "\n",
    "def get_bureau_day_amt_agg(bureau):     \n",
    "\n",
    "    bureau_grp = bureau.groupby('SK_ID_CURR')\n",
    "    bureau_day_amt_agg = bureau_grp.agg(bureau_agg_dict)\n",
    "    bureau_day_amt_agg.columns = ['BUREAU_' + ('_').join(column).upper() for column in bureau_day_amt_agg.columns.ravel()]\n",
    "    bureau_day_amt_agg = bureau_day_amt_agg.reset_index()\n",
    "    \n",
    "    return bureau_day_amt_agg\n",
    "\n",
    "\n",
    "def get_bureau_active_agg(bureau):\n",
    "    \n",
    "    cond_active = bureau['CREDIT_ACTIVE'] == 'Active'\n",
    "    bureau_active_grp = bureau[cond_active].groupby('SK_ID_CURR')\n",
    "    bureau_active_agg = bureau_active_grp.agg(bureau_agg_dict)\n",
    "    bureau_active_agg.columns = ['BUREAU_ACT_' + ('_').join(column).upper() for column in bureau_active_agg.columns.ravel()]\n",
    "    bureau_active_agg = bureau_active_agg.reset_index()\n",
    "    \n",
    "    return bureau_active_agg\n",
    "\n",
    "\n",
    "def get_bureau_bal_agg(bureau, bureau_bal):\n",
    "    \n",
    "    bureau_bal = bureau_bal.merge(bureau[['SK_ID_CURR', 'SK_ID_BUREAU']], on='SK_ID_BUREAU', how='left')\n",
    "    bureau_bal['BUREAU_BAL_IS_DPD'] = bureau_bal['STATUS'].apply(lambda x: 1 if x in ['1', '2', '3', '4', '5'] else 0)\n",
    "    bureau_bal['BUREAU_BAL_IS_DPD_OVER120'] = bureau_bal['STATUS'].apply(lambda x: 1 if x == '5' else 0)\n",
    "    bureau_bal_grp = bureau_bal.groupby('SK_ID_CURR')\n",
    "    bureau_bal_agg = bureau_bal_grp.agg(bureau_bal_agg_dict)\n",
    "    bureau_bal_agg.columns = ['BUREAU_BAL_' + ('_').join(column).upper() for column in bureau_bal_agg.columns.ravel()]\n",
    "    bureau_bal_agg = bureau_bal_agg.reset_index()\n",
    "    \n",
    "    return bureau_bal_agg\n",
    "\n",
    "\n",
    "def get_bureau_agg(bureau, bureau_bal):\n",
    "    \n",
    "    bureau = get_bureau_processed(bureau)\n",
    "    bureau_day_amt_agg = get_bureau_day_amt_agg(bureau)\n",
    "    bureau_active_agg = get_bureau_active_agg(bureau)\n",
    "    bureau_bal_agg = get_bureau_bal_agg(bureau, bureau_bal)\n",
    "    bureau_agg = bureau_day_amt_agg.merge(bureau_active_agg, on='SK_ID_CURR', how='left')\n",
    "    bureau_agg = bureau_agg.merge(bureau_bal_agg, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    return bureau_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_bal_agg(pos_ball):\n",
    "    \n",
    "    pos_bal['POS_IS_DPD'] = pos_bal['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    pos_bal['POS_IS_DPD_UNDER_120'] = pos_bal['SK_DPD'].apply(lambda x: 1 if (x > 0) & (x < 120) else 0)\n",
    "    pos_bal['POS_IS_DPD_OVER_120'] = pos_bal['SK_DPD'].apply(lambda x: 1 if x >= 120 else 0)\n",
    "\n",
    "    pos_bal_grp = pos_bal.groupby('SK_ID_CURR')\n",
    "    pos_bal_agg_dict = {\n",
    "        'SK_ID_CURR': ['count'], \n",
    "        'MONTHS_BALANCE': ['min', 'mean', 'max'], \n",
    "        'SK_DPD': ['min', 'max', 'mean'],\n",
    "\n",
    "        'POS_IS_DPD': ['mean', 'sum'],\n",
    "        'POS_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'POS_IS_DPD_OVER_120': ['mean', 'sum'],\n",
    "    }\n",
    "\n",
    "    pos_bal_agg = pos_bal_grp.agg(pos_bal_agg_dict)\n",
    "    pos_bal_agg.columns = [('POS_') + ('_').join(column).upper() for column in pos_bal_agg.columns.ravel()]\n",
    "\n",
    "    cond_months = pos_bal['MONTHS_BALANCE'] > -20\n",
    "    pos_bal_m20_grp = pos_bal[cond_months].groupby('SK_ID_CURR')\n",
    "    pos_bal_agg_dict = {\n",
    "        'SK_ID_CURR': ['count'], \n",
    "        'MONTHS_BALANCE': ['min', 'mean', 'max'], \n",
    "        'SK_DPD': ['min', 'max', 'mean'],\n",
    "\n",
    "        'POS_IS_DPD': ['mean', 'sum'],\n",
    "        'POS_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'POS_IS_DPD_OVER_120': ['mean', 'sum'],\n",
    "    }\n",
    "\n",
    "    pos_bal_m20_agg = pos_bal_m20_grp.agg(pos_bal_agg_dict)\n",
    "    pos_bal_m20_agg.columns = [('POS_M20')+('_').join(column).upper() for column in pos_bal_m20_agg.columns.ravel()]\n",
    "\n",
    "    pos_bal_agg = pos_bal_agg.merge(pos_bal_m20_agg, on='SK_ID_CURR', how='left')\n",
    "    pos_bal_agg = pos_bal_agg.reset_index()\n",
    "    \n",
    "    return pos_bal_agg\n",
    "\n",
    "\n",
    "def get_install_agg(install):\n",
    "\n",
    "    install['AMT_DIFF'] = install['AMT_INSTALMENT'] - install['AMT_PAYMENT']\n",
    "    install['AMT_RATIO'] = (install['AMT_PAYMENT'] + 1) / (install['AMT_INSTALMENT'] + 1)\n",
    "\n",
    "    install['SK_DPD'] = install['DAYS_ENTRY_PAYMENT'] - install['DAYS_INSTALMENT']\n",
    "    \n",
    "    install['INS_IS_DPD'] = install['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    install['INS_IS_DPD_UNDER_120'] = install['SK_DPD'].apply(lambda x: 1 if (x > 0) & (x < 120) else 0)\n",
    "    install['INS_IS_DPD_OVER_120'] = install['SK_DPD'].apply(lambda x: 1 if x >= 120 else 0)\n",
    "\n",
    "    install_grp = install.groupby('SK_ID_CURR')\n",
    "    install_agg_dict = {\n",
    "        'SK_ID_CURR': ['count'],\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'], \n",
    "        'DAYS_ENTRY_PAYMENT': ['mean', 'max', 'sum'],\n",
    "        'DAYS_INSTALMENT': ['mean', 'max', 'sum'],\n",
    "        'AMT_INSTALMENT': ['mean', 'max', 'sum'],\n",
    "        'AMT_PAYMENT': ['mean', 'max','sum'],\n",
    "\n",
    "        'AMT_DIFF': ['mean','min', 'max','sum'],\n",
    "        'AMT_RATIO':[ 'mean', 'max'],\n",
    "        'SK_DPD': ['mean', 'min', 'max'],\n",
    "        'INS_IS_DPD': ['mean', 'sum'],\n",
    "        'INS_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'INS_IS_DPD_OVER_120': ['mean', 'sum'],\n",
    "    }\n",
    "\n",
    "    install_agg = install_grp.agg(install_agg_dict)\n",
    "    install_agg.columns = [('INS_') + ('_').join(column).upper() for column in install_agg.columns.ravel()]\n",
    "\n",
    "    cond_day = install['DAYS_ENTRY_PAYMENT'] >= -365\n",
    "    install_d365_grp = install[cond_day].groupby('SK_ID_CURR')\n",
    "    install_agg_dict = {\n",
    "        'SK_ID_CURR': ['count'],\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'], \n",
    "        'DAYS_ENTRY_PAYMENT': ['mean', 'max', 'sum'],\n",
    "        'DAYS_INSTALMENT': ['mean', 'max', 'sum'],\n",
    "        'AMT_INSTALMENT': ['mean', 'max', 'sum'],\n",
    "        'AMT_PAYMENT': ['mean', 'max','sum'],\n",
    "\n",
    "        'AMT_DIFF': ['mean','min', 'max','sum'],\n",
    "        'AMT_RATIO':[ 'mean', 'max'],\n",
    "        'SK_DPD': ['mean', 'min', 'max'],\n",
    "        'INS_IS_DPD': ['mean', 'sum'],\n",
    "        'INS_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'INS_IS_DPD_OVER_120': ['mean', 'sum'],\n",
    "    }\n",
    "\n",
    "    install_d365_agg = install_d365_grp.agg(install_agg_dict)\n",
    "    install_d365_agg.columns = [('INS_d365')+('_').join(column).upper() for column in install_d365_agg. columns.ravel()]\n",
    "\n",
    "    install_agg = install_agg.merge(install_d365_agg, on='SK_ID_CURR', how='left')\n",
    "    install_agg = install_agg.reset_index()\n",
    "    \n",
    "    return install_agg\n",
    "\n",
    "\n",
    "def get_card_bal_agg(card_bal):\n",
    "\n",
    "    card_bal['BALANCE_LIMIT_RATIO'] = card_bal['AMT_BALANCE'] / card_bal['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "    card_bal['DRAWING_LIMIT_RATIO'] = card_bal['AMT_DRAWINGS_CURRENT'] / card_bal['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "\n",
    "    card_bal['CARD_IS_DPD'] = card_bal['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    card_bal['CARD_IS_DPD_UNDER_120'] = card_bal['SK_DPD'].apply(lambda x: 1 if (x > 0) & (x < 120) else 0)\n",
    "    card_bal['CARD_IS_DPD_OVER_120'] = card_bal['SK_DPD'].apply(lambda x: 1 if x >= 120 else 0)\n",
    "\n",
    "    card_bal_grp = card_bal.groupby('SK_ID_CURR')\n",
    "    card_bal_agg_dict = {\n",
    "        'SK_ID_CURR': ['count'],\n",
    "        'AMT_BALANCE': ['max'],\n",
    "        'AMT_CREDIT_LIMIT_ACTUAL': ['max'],\n",
    "        'AMT_DRAWINGS_ATM_CURRENT': ['max', 'sum'],\n",
    "        'AMT_DRAWINGS_CURRENT': ['max', 'sum'],\n",
    "        'AMT_DRAWINGS_POS_CURRENT': ['max', 'sum'],\n",
    "        'AMT_INST_MIN_REGULARITY': ['max', 'mean'],\n",
    "        'AMT_PAYMENT_TOTAL_CURRENT': ['max','sum'],\n",
    "        'AMT_TOTAL_RECEIVABLE': ['max', 'mean'],\n",
    "        'CNT_DRAWINGS_ATM_CURRENT': ['max','sum'],\n",
    "        'CNT_DRAWINGS_CURRENT': ['max', 'mean', 'sum'],\n",
    "        'CNT_DRAWINGS_POS_CURRENT': ['mean'],\n",
    "        'SK_DPD': ['mean', 'max', 'sum'],\n",
    "\n",
    "        'BALANCE_LIMIT_RATIO': ['min','max'],\n",
    "        'DRAWING_LIMIT_RATIO': ['min', 'max'],\n",
    "        'CARD_IS_DPD': ['mean', 'sum'],\n",
    "        'CARD_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'CARD_IS_DPD_OVER_120': ['mean', 'sum'],\n",
    "    }\n",
    "\n",
    "    card_bal_agg = card_bal_grp.agg(card_bal_agg_dict)\n",
    "    card_bal_agg.columns = [('CARD_') + ('_').join(column).upper() for column in card_bal_agg.columns.ravel()]\n",
    "    \n",
    "    card_bal_agg = card_bal_agg.reset_index()\n",
    "\n",
    "    cond_month = card_bal['MONTHS_BALANCE'] >= -3\n",
    "    card_bal_m3_grp = card_bal[cond_month].groupby('SK_ID_CURR')\n",
    "\n",
    "    card_bal_m3_agg = card_bal_m3_grp.agg(card_bal_agg_dict)\n",
    "    card_bal_m3_agg.columns = ['CARD_M3'+('_').join(column).upper() for column in card_bal_m3_agg.  columns.ravel()]\n",
    "\n",
    "    card_bal_agg = card_bal_agg.merge(card_bal_m3_agg, on='SK_ID_CURR', how='left')\n",
    "    card_bal_agg = card_bal_agg.reset_index()\n",
    "    \n",
    "    return card_bal_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apps_all_with_all_agg(apps, prev, bureau, bureau_bal, pos_bal, install, card_bal):\n",
    "    \n",
    "    apps_all = get_apps_processed(apps)\n",
    "    prev_agg = get_prev_agg(prev)\n",
    "    bureau_agg = get_bureau_agg(bureau, bureau_bal)\n",
    "    pos_bal_agg = get_pos_bal_agg(pos_bal)\n",
    "    install_agg = get_install_agg(install)\n",
    "    card_bal_agg = get_card_bal_agg(card_bal)\n",
    "    \n",
    "    print(f'prev_agg shape: {prev_agg.shape}\\nbureau_agg shape: {bureau_agg.shape}')\n",
    "    print(f'pos_bal_agg shape: {pos_bal_agg.shape}\\ninstall_agg shape: {install_agg.shape}\\ncard_bal_agg shape: {card_bal_agg.shape}')\n",
    "    print(f'apps_all before merge shape: {apps_all.shape}')\n",
    "    \n",
    "    apps_all = apps_all.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
    "    apps_all = apps_all.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
    "    apps_all = apps_all.merge(pos_bal_agg, on='SK_ID_CURR', how='left')\n",
    "    apps_all = apps_all.merge(install_agg, on='SK_ID_CURR', how='left')\n",
    "    apps_all = apps_all.merge(card_bal_agg, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    print(f'apps_all after merge with all shape: {apps_all.shape}')\n",
    "    \n",
    "    return apps_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_agg shape: (338857, 42)\n",
      "bureau_agg shape: (305811, 101)\n",
      "pos_bal_agg shape: (337252, 27)\n",
      "install_agg shape: (339587, 59)\n",
      "card_bal_agg shape: (103558, 70)\n",
      "apps_all before merge shape: (356255, 136)\n",
      "apps_all after merge with all shape: (356255, 430)\n"
     ]
    }
   ],
   "source": [
    "apps, prev, bureau, bureau_balance, pos_bal, install, card_bal = get_dataset()\n",
    "\n",
    "apps_all = get_apps_all_with_all_agg(apps, prev, bureau, bureau_balance, pos_bal, install, card_bal)\n",
    "apps_all = get_apps_all_encoded(apps_all)\n",
    "apps_all_train, apps_all_test = get_apps_all_train_test(apps_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train_apps_all_with_oof(apps_all_train, apps_all_test, nfolds=5):\n",
    "    ftr_app = apps_all_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
    "    target_app = apps_all_train['TARGET']\n",
    "    \n",
    "    folds = KFold(n_splits=nfolds, shuffle=True, random_state=0)\n",
    "    oof_preds = np.zeros(ftr_app.shape[0])\n",
    "    test_preds = np.zeros(apps_all_test.shape[0])\n",
    "    \n",
    "    clf = LGBMClassifier(\n",
    "        n_jobs=-1, \n",
    "        n_estimators=4000, \n",
    "        learning_rate=0.01,\n",
    "        # from hyper_parameter_tuning (BayesianOptimization)\n",
    "        colsample_bytree=0.601,\n",
    "        max_bin=348, \n",
    "        max_depth=12, \n",
    "        min_child_samples=107, \n",
    "        min_child_weight=8, \n",
    "        num_leaves=61, \n",
    "        reg_alpha=11.964, \n",
    "        reg_lambda=5.513, \n",
    "        subsample=0.773,\n",
    "        silent=-1, \n",
    "        verbose=-1,\n",
    "    )\n",
    "    \n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(folds.split(ftr_app)):\n",
    "        \n",
    "        print(f'##### iteration {fold_idx} start')\n",
    "        train_x = ftr_app.iloc[train_idx, :]\n",
    "        train_y = target_app.iloc[train_idx]\n",
    "        valid_x = ftr_app.iloc[valid_idx, :]\n",
    "        valid_y = target_app.iloc[valid_idx]\n",
    "        \n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "                eval_metric='auc', verbose=200, early_stopping_rounds=200)\n",
    "        test_preds += clf.predict_proba(\n",
    "            apps_all_test.drop('SK_ID_CURR', axis=1), num_iteration=clf.best_iteration_\n",
    "        )[:, 1] / folds.n_splits\n",
    "        \n",
    "    return clf, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### iteration 0 start\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.79136\ttraining's binary_logloss: 0.241052\tvalid_1's auc: 0.768589\tvalid_1's binary_logloss: 0.242339\n",
      "[400]\ttraining's auc: 0.811718\ttraining's binary_logloss: 0.230787\tvalid_1's auc: 0.781043\tvalid_1's binary_logloss: 0.236315\n",
      "[600]\ttraining's auc: 0.825744\ttraining's binary_logloss: 0.224431\tvalid_1's auc: 0.787245\tvalid_1's binary_logloss: 0.233751\n",
      "[800]\ttraining's auc: 0.837498\ttraining's binary_logloss: 0.219405\tvalid_1's auc: 0.790912\tvalid_1's binary_logloss: 0.232392\n",
      "[1000]\ttraining's auc: 0.847959\ttraining's binary_logloss: 0.215002\tvalid_1's auc: 0.793176\tvalid_1's binary_logloss: 0.231556\n",
      "[1200]\ttraining's auc: 0.857347\ttraining's binary_logloss: 0.210988\tvalid_1's auc: 0.794693\tvalid_1's binary_logloss: 0.231013\n",
      "[1400]\ttraining's auc: 0.865878\ttraining's binary_logloss: 0.207244\tvalid_1's auc: 0.795744\tvalid_1's binary_logloss: 0.230628\n",
      "[1600]\ttraining's auc: 0.873768\ttraining's binary_logloss: 0.203773\tvalid_1's auc: 0.796476\tvalid_1's binary_logloss: 0.230382\n",
      "[1800]\ttraining's auc: 0.880763\ttraining's binary_logloss: 0.200554\tvalid_1's auc: 0.796901\tvalid_1's binary_logloss: 0.230215\n",
      "[2000]\ttraining's auc: 0.887335\ttraining's binary_logloss: 0.197494\tvalid_1's auc: 0.797215\tvalid_1's binary_logloss: 0.230089\n",
      "[2200]\ttraining's auc: 0.89338\ttraining's binary_logloss: 0.194543\tvalid_1's auc: 0.797509\tvalid_1's binary_logloss: 0.229993\n",
      "[2400]\ttraining's auc: 0.899259\ttraining's binary_logloss: 0.191682\tvalid_1's auc: 0.797795\tvalid_1's binary_logloss: 0.229908\n",
      "[2600]\ttraining's auc: 0.904845\ttraining's binary_logloss: 0.188865\tvalid_1's auc: 0.79787\tvalid_1's binary_logloss: 0.229876\n",
      "[2800]\ttraining's auc: 0.909998\ttraining's binary_logloss: 0.186182\tvalid_1's auc: 0.797945\tvalid_1's binary_logloss: 0.229839\n",
      "[3000]\ttraining's auc: 0.914871\ttraining's binary_logloss: 0.183562\tvalid_1's auc: 0.798168\tvalid_1's binary_logloss: 0.229752\n",
      "[3200]\ttraining's auc: 0.919583\ttraining's binary_logloss: 0.180994\tvalid_1's auc: 0.798209\tvalid_1's binary_logloss: 0.229744\n",
      "[3400]\ttraining's auc: 0.923843\ttraining's binary_logloss: 0.178553\tvalid_1's auc: 0.798216\tvalid_1's binary_logloss: 0.229732\n",
      "[3600]\ttraining's auc: 0.927911\ttraining's binary_logloss: 0.176151\tvalid_1's auc: 0.798218\tvalid_1's binary_logloss: 0.229727\n",
      "Early stopping, best iteration is:\n",
      "[3481]\ttraining's auc: 0.925535\ttraining's binary_logloss: 0.177574\tvalid_1's auc: 0.79827\tvalid_1's binary_logloss: 0.229715\n",
      "##### iteration 1 start\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.791886\ttraining's binary_logloss: 0.239995\tvalid_1's auc: 0.769242\tvalid_1's binary_logloss: 0.246044\n",
      "[400]\ttraining's auc: 0.812232\ttraining's binary_logloss: 0.229662\tvalid_1's auc: 0.781146\tvalid_1's binary_logloss: 0.240036\n",
      "[600]\ttraining's auc: 0.826238\ttraining's binary_logloss: 0.223268\tvalid_1's auc: 0.786928\tvalid_1's binary_logloss: 0.237653\n",
      "[800]\ttraining's auc: 0.837891\ttraining's binary_logloss: 0.218249\tvalid_1's auc: 0.790212\tvalid_1's binary_logloss: 0.236437\n",
      "[1000]\ttraining's auc: 0.848261\ttraining's binary_logloss: 0.213831\tvalid_1's auc: 0.792415\tvalid_1's binary_logloss: 0.235631\n",
      "[1200]\ttraining's auc: 0.857674\ttraining's binary_logloss: 0.20978\tvalid_1's auc: 0.79367\tvalid_1's binary_logloss: 0.235176\n",
      "[1400]\ttraining's auc: 0.866214\ttraining's binary_logloss: 0.206045\tvalid_1's auc: 0.794536\tvalid_1's binary_logloss: 0.234874\n",
      "[1600]\ttraining's auc: 0.874025\ttraining's binary_logloss: 0.202559\tvalid_1's auc: 0.795085\tvalid_1's binary_logloss: 0.234679\n",
      "[1800]\ttraining's auc: 0.881095\ttraining's binary_logloss: 0.199318\tvalid_1's auc: 0.795558\tvalid_1's binary_logloss: 0.234535\n",
      "[2000]\ttraining's auc: 0.887682\ttraining's binary_logloss: 0.196226\tvalid_1's auc: 0.795867\tvalid_1's binary_logloss: 0.234435\n",
      "[2200]\ttraining's auc: 0.89374\ttraining's binary_logloss: 0.193289\tvalid_1's auc: 0.796022\tvalid_1's binary_logloss: 0.234373\n",
      "[2400]\ttraining's auc: 0.899471\ttraining's binary_logloss: 0.190476\tvalid_1's auc: 0.79608\tvalid_1's binary_logloss: 0.234358\n",
      "[2600]\ttraining's auc: 0.90498\ttraining's binary_logloss: 0.187704\tvalid_1's auc: 0.796132\tvalid_1's binary_logloss: 0.23434\n",
      "Early stopping, best iteration is:\n",
      "[2558]\ttraining's auc: 0.903808\ttraining's binary_logloss: 0.188292\tvalid_1's auc: 0.796151\tvalid_1's binary_logloss: 0.234325\n",
      "##### iteration 2 start\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.792511\ttraining's binary_logloss: 0.239801\tvalid_1's auc: 0.76714\tvalid_1's binary_logloss: 0.24666\n",
      "[400]\ttraining's auc: 0.813138\ttraining's binary_logloss: 0.229419\tvalid_1's auc: 0.77844\tvalid_1's binary_logloss: 0.240861\n",
      "[600]\ttraining's auc: 0.827152\ttraining's binary_logloss: 0.223041\tvalid_1's auc: 0.783631\tvalid_1's binary_logloss: 0.238664\n",
      "[800]\ttraining's auc: 0.838988\ttraining's binary_logloss: 0.217968\tvalid_1's auc: 0.786719\tvalid_1's binary_logloss: 0.237473\n",
      "[1000]\ttraining's auc: 0.849487\ttraining's binary_logloss: 0.213506\tvalid_1's auc: 0.788428\tvalid_1's binary_logloss: 0.236801\n",
      "[1200]\ttraining's auc: 0.859028\ttraining's binary_logloss: 0.209434\tvalid_1's auc: 0.78943\tvalid_1's binary_logloss: 0.236404\n",
      "[1400]\ttraining's auc: 0.867748\ttraining's binary_logloss: 0.205637\tvalid_1's auc: 0.790159\tvalid_1's binary_logloss: 0.236119\n",
      "[1600]\ttraining's auc: 0.875625\ttraining's binary_logloss: 0.202095\tvalid_1's auc: 0.790614\tvalid_1's binary_logloss: 0.235916\n",
      "[1800]\ttraining's auc: 0.882812\ttraining's binary_logloss: 0.198804\tvalid_1's auc: 0.790937\tvalid_1's binary_logloss: 0.235774\n",
      "[2000]\ttraining's auc: 0.889512\ttraining's binary_logloss: 0.195673\tvalid_1's auc: 0.791212\tvalid_1's binary_logloss: 0.2357\n",
      "[2200]\ttraining's auc: 0.895631\ttraining's binary_logloss: 0.192705\tvalid_1's auc: 0.79141\tvalid_1's binary_logloss: 0.235642\n",
      "[2400]\ttraining's auc: 0.901263\ttraining's binary_logloss: 0.189881\tvalid_1's auc: 0.791563\tvalid_1's binary_logloss: 0.235594\n",
      "Early stopping, best iteration is:\n",
      "[2356]\ttraining's auc: 0.900036\ttraining's binary_logloss: 0.190498\tvalid_1's auc: 0.791572\tvalid_1's binary_logloss: 0.235593\n",
      "##### iteration 3 start\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.792124\ttraining's binary_logloss: 0.239725\tvalid_1's auc: 0.768742\tvalid_1's binary_logloss: 0.247114\n",
      "[400]\ttraining's auc: 0.812564\ttraining's binary_logloss: 0.229426\tvalid_1's auc: 0.779813\tvalid_1's binary_logloss: 0.241343\n",
      "[600]\ttraining's auc: 0.826899\ttraining's binary_logloss: 0.222982\tvalid_1's auc: 0.785381\tvalid_1's binary_logloss: 0.239021\n",
      "[800]\ttraining's auc: 0.838841\ttraining's binary_logloss: 0.217888\tvalid_1's auc: 0.788431\tvalid_1's binary_logloss: 0.237876\n",
      "[1000]\ttraining's auc: 0.84922\ttraining's binary_logloss: 0.213454\tvalid_1's auc: 0.790567\tvalid_1's binary_logloss: 0.23711\n",
      "[1200]\ttraining's auc: 0.858677\ttraining's binary_logloss: 0.209427\tvalid_1's auc: 0.791933\tvalid_1's binary_logloss: 0.236624\n",
      "[1400]\ttraining's auc: 0.867126\ttraining's binary_logloss: 0.205715\tvalid_1's auc: 0.792693\tvalid_1's binary_logloss: 0.236325\n",
      "[1600]\ttraining's auc: 0.87478\ttraining's binary_logloss: 0.202261\tvalid_1's auc: 0.793318\tvalid_1's binary_logloss: 0.23609\n",
      "[1800]\ttraining's auc: 0.881824\ttraining's binary_logloss: 0.199006\tvalid_1's auc: 0.793837\tvalid_1's binary_logloss: 0.235923\n",
      "[2000]\ttraining's auc: 0.888312\ttraining's binary_logloss: 0.195952\tvalid_1's auc: 0.794197\tvalid_1's binary_logloss: 0.235817\n",
      "[2200]\ttraining's auc: 0.894358\ttraining's binary_logloss: 0.193018\tvalid_1's auc: 0.794361\tvalid_1's binary_logloss: 0.23575\n",
      "[2400]\ttraining's auc: 0.900306\ttraining's binary_logloss: 0.190153\tvalid_1's auc: 0.794666\tvalid_1's binary_logloss: 0.235659\n",
      "[2600]\ttraining's auc: 0.905657\ttraining's binary_logloss: 0.187428\tvalid_1's auc: 0.794703\tvalid_1's binary_logloss: 0.235659\n",
      "Early stopping, best iteration is:\n",
      "[2436]\ttraining's auc: 0.901273\ttraining's binary_logloss: 0.189662\tvalid_1's auc: 0.794691\tvalid_1's binary_logloss: 0.235646\n",
      "##### iteration 4 start\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.792436\ttraining's binary_logloss: 0.239511\tvalid_1's auc: 0.769039\tvalid_1's binary_logloss: 0.247989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's auc: 0.81279\ttraining's binary_logloss: 0.229234\tvalid_1's auc: 0.779883\tvalid_1's binary_logloss: 0.242149\n",
      "[600]\ttraining's auc: 0.826902\ttraining's binary_logloss: 0.222838\tvalid_1's auc: 0.785408\tvalid_1's binary_logloss: 0.239817\n",
      "[800]\ttraining's auc: 0.838562\ttraining's binary_logloss: 0.217787\tvalid_1's auc: 0.788623\tvalid_1's binary_logloss: 0.238576\n",
      "[1000]\ttraining's auc: 0.848908\ttraining's binary_logloss: 0.213373\tvalid_1's auc: 0.790658\tvalid_1's binary_logloss: 0.237822\n",
      "[1200]\ttraining's auc: 0.858486\ttraining's binary_logloss: 0.209293\tvalid_1's auc: 0.79205\tvalid_1's binary_logloss: 0.237316\n",
      "[1400]\ttraining's auc: 0.866997\ttraining's binary_logloss: 0.205526\tvalid_1's auc: 0.792993\tvalid_1's binary_logloss: 0.236975\n",
      "[1600]\ttraining's auc: 0.874891\ttraining's binary_logloss: 0.202042\tvalid_1's auc: 0.793505\tvalid_1's binary_logloss: 0.236768\n",
      "[1800]\ttraining's auc: 0.882164\ttraining's binary_logloss: 0.198765\tvalid_1's auc: 0.793742\tvalid_1's binary_logloss: 0.236665\n",
      "[2000]\ttraining's auc: 0.888708\ttraining's binary_logloss: 0.195668\tvalid_1's auc: 0.793992\tvalid_1's binary_logloss: 0.236586\n",
      "[2200]\ttraining's auc: 0.894944\ttraining's binary_logloss: 0.192687\tvalid_1's auc: 0.794204\tvalid_1's binary_logloss: 0.23653\n",
      "[2400]\ttraining's auc: 0.900868\ttraining's binary_logloss: 0.189802\tvalid_1's auc: 0.794296\tvalid_1's binary_logloss: 0.236508\n",
      "[2600]\ttraining's auc: 0.906629\ttraining's binary_logloss: 0.186982\tvalid_1's auc: 0.794448\tvalid_1's binary_logloss: 0.236465\n",
      "[2800]\ttraining's auc: 0.91195\ttraining's binary_logloss: 0.184254\tvalid_1's auc: 0.794485\tvalid_1's binary_logloss: 0.236452\n",
      "Early stopping, best iteration is:\n",
      "[2682]\ttraining's auc: 0.908854\ttraining's binary_logloss: 0.185855\tvalid_1's auc: 0.794557\tvalid_1's binary_logloss: 0.236426\n"
     ]
    }
   ],
   "source": [
    "clf, test_preds = train_apps_all_with_oof(apps_all_train, apps_all_test, nfolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_all_test['TARGET'] = test_preds\n",
    "apps_all_test[['SK_ID_CURR', 'TARGET']].to_csv('../result/out_of_prediction_result_01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
