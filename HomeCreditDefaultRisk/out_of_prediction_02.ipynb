{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    \n",
    "    prev_dtype = {\n",
    "        'SK_ID_PREV': np.uint32, 'SK_ID_CURR': np.uint32, 'HOUR_APPR_PROCESS_START': np.int32, 'NFLAG_LAST_APPL_IN_DAY': np.int32,\n",
    "        'DAYS_DECISION': np.int32, 'SELLERPLACE_AREA': np.int32, 'AMT_ANNUITY': np.float32, 'AMT_APPLICATION': np.float32,\n",
    "        'AMT_CREDIT': np.float32, 'AMT_DOWN_PAYMENT': np.float32, 'AMT_GOODS_PRICE': np.float32, 'RATE_DOWN_PAYMENT': np.float32,\n",
    "        'RATE_INTEREST_PRIMARY': np.float32, 'RATE_INTEREST_PRIVILEGED': np.float32, 'CNT_PAYMENT': np.float32,\n",
    "        'DAYS_FIRST_DRAWING': np.float32, 'DAYS_FIRST_DUE': np.float32, 'DAYS_LAST_DUE_1ST_VERSION': np.float32,\n",
    "        'DAYS_LAST_DUE': np.float32, 'DAYS_TERMINATION': np.float32, 'NFLAG_INSURED_ON_APPROVAL': np.float32\n",
    "    }\n",
    "    \n",
    "    bureau_dtype = {\n",
    "        'SK_ID_CURR': np.uint32, 'SK_ID_BUREAU': np.uint32, 'DAYS_CREDIT': np.int32,'CREDIT_DAY_OVERDUE': np.int32,\n",
    "        'CNT_CREDIT_PROLONG': np.int32, 'DAYS_CREDIT_UPDATE': np.int32, 'DAYS_CREDIT_ENDDATE': np.float32,\n",
    "        'DAYS_ENDDATE_FACT': np.float32, 'AMT_CREDIT_MAX_OVERDUE': np.float32, 'AMT_CREDIT_SUM': np.float32,\n",
    "        'AMT_CREDIT_SUM_DEBT': np.float32, 'AMT_CREDIT_SUM_LIMIT': np.float32, 'AMT_CREDIT_SUM_OVERDUE': np.float32,\n",
    "        'AMT_ANNUITY': np.float32\n",
    "    }\n",
    "    \n",
    "    bureau_bal_dtype = {\n",
    "        'SK_ID_BUREAU': np.int32, 'MONTHS_BALANCE': np.int32,\n",
    "    }\n",
    "    \n",
    "    pos_dtype = {\n",
    "        'SK_ID_PREV': np.uint32, 'SK_ID_CURR': np.uint32, 'MONTHS_BALANCE': np.int32, 'SK_DPD': np.int32,\n",
    "        'SK_DPD_DEF': np.int32, 'CNT_INSTALMENT': np.float32,'CNT_INSTALMENT_FUTURE': np.float32,\n",
    "    }\n",
    "    \n",
    "    install_dtype = {\n",
    "        'SK_ID_PREV': np.uint32, 'SK_ID_CURR': np.uint32, 'NUM_INSTALMENT_NUMBER': np.int32, 'NUM_INSTALMENT_VERSION': np.float32,\n",
    "        'DAYS_INSTALMENT': np.float32, 'DAYS_ENTRY_PAYMENT': np.float32, 'AMT_INSTALMENT': np.float32, 'AMT_PAYMENT': np.float32,\n",
    "    }\n",
    "    \n",
    "    card_dtype = {\n",
    "        'SK_ID_PREV': np.uint32, 'SK_ID_CURR': np.uint32, 'MONTHS_BALANCE': np.int16,\n",
    "        'AMT_CREDIT_LIMIT_ACTUAL': np.int32, 'CNT_DRAWINGS_CURRENT': np.int32, 'SK_DPD': np.int32,'SK_DPD_DEF': np.int32,\n",
    "        'AMT_BALANCE': np.float32, 'AMT_DRAWINGS_ATM_CURRENT': np.float32, 'AMT_DRAWINGS_CURRENT': np.float32,\n",
    "        'AMT_DRAWINGS_OTHER_CURRENT': np.float32, 'AMT_DRAWINGS_POS_CURRENT': np.float32, 'AMT_INST_MIN_REGULARITY': np.float32,\n",
    "        'AMT_PAYMENT_CURRENT': np.float32, 'AMT_PAYMENT_TOTAL_CURRENT': np.float32, 'AMT_RECEIVABLE_PRINCIPAL': np.float32,\n",
    "        'AMT_RECIVABLE': np.float32, 'AMT_TOTAL_RECEIVABLE': np.float32, 'CNT_DRAWINGS_ATM_CURRENT': np.float32,\n",
    "        'CNT_DRAWINGS_OTHER_CURRENT': np.float32, 'CNT_DRAWINGS_POS_CURRENT': np.float32, 'CNT_INSTALMENT_MATURE_CUM': np.float32,\n",
    "    }\n",
    "    \n",
    "    app_train = pd.read_csv('../data/home-credit-default-risk/application_train.csv')\n",
    "    app_test = pd.read_csv('../data/home-credit-default-risk/application_test.csv')\n",
    "    apps = pd.concat([app_train, app_test])\n",
    "    prev = pd.read_csv('../data/home-credit-default-risk/previous_application.csv', dtype=prev_dtype)\n",
    "    bureau = pd.read_csv('../data/home-credit-default-risk/bureau.csv', dtype=bureau_dtype)\n",
    "    bureau_balance = pd.read_csv('../data/home-credit-default-risk/bureau_balance.csv', dtype=bureau_bal_dtype)\n",
    "    pos_bal = pd.read_csv('../data/home-credit-default-risk/POS_CASH_balance.csv', dtype=pos_dtype)\n",
    "    install = pd.read_csv('../data/home-credit-default-risk/installments_payments.csv', dtype=install_dtype)\n",
    "    card_bal = pd.read_csv('../data/home-credit-default-risk/credit_card_balance.csv', dtype=card_dtype)\n",
    "    \n",
    "    return apps, prev, bureau, bureau_balance, pos_bal, install, card_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "def get_apps_processed(apps):\n",
    "    apps['APPS_EXT_SOURCE_MEAN'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "    apps['APPS_EXT_SOURCE_STD'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "    apps['APPS_EXT_SOURCE_STD'] = apps['APPS_EXT_SOURCE_STD'].fillna(apps['APPS_EXT_SOURCE_STD'].mean())\n",
    "    \n",
    "    apps['APPS_ANNUITY_CREDIT_RATIO'] = apps['AMT_ANNUITY'] / apps['AMT_CREDIT']\n",
    "    apps['APPS_GOODS_CREDIT_RATIO'] = apps['AMT_GOODS_PRICE'] / apps['AMT_CREDIT']\n",
    "    apps['APPS_CREDIT_GOODS_DIFF'] = apps['AMT_CREDIT'] - apps['AMT_GOODS_PRICE']\n",
    "    \n",
    "    apps['APPS_ANNUITY_INCOME_RATIO'] = apps['AMT_ANNUITY'] / apps['AMT_INCOME_TOTAL']\n",
    "    apps['APPS_CREDIT_INCOME_RATIO'] = apps['AMT_CREDIT'] / apps['AMT_INCOME_TOTAL']\n",
    "    apps['APPS_GOODS_INCOME_RATIO'] = apps['AMT_GOODS_PRICE'] / apps['AMT_INCOME_TOTAL']\n",
    "    apps['APPS_CNT_FAM_INCOME_RATIO'] = apps['AMT_INCOME_TOTAL'] / apps['CNT_FAM_MEMBERS']\n",
    "    \n",
    "    apps['APPS_EMPLOYED_BIRTH_RATIO'] = apps['DAYS_EMPLOYED'] / apps['DAYS_BIRTH']\n",
    "    apps['APPS_INCOME_EMPLOYED_RATIO'] = apps['AMT_INCOME_TOTAL'] / apps['DAYS_EMPLOYED']\n",
    "    apps['APPS_INCOME_BIRTH_RATIO'] = apps['AMT_INCOME_TOTAL'] / apps['DAYS_BIRTH']\n",
    "    apps['APPS_CAR_BIRTH_RATIO'] = apps['OWN_CAR_AGE'] / apps['DAYS_BIRTH']\n",
    "    apps['APPS_CAR_EMPLOYED_RATIO'] = apps['OWN_CAR_AGE'] / apps['DAYS_EMPLOYED']\n",
    "    \n",
    "    return apps\n",
    "\n",
    "\n",
    "def get_prev_processed(prev):\n",
    "    \n",
    "    prev['PREV_CREDIT_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\n",
    "    prev['PREV_GOODS_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_GOODS_PRICE']\n",
    "    prev['PREV_CREDIT_APPL_RATIO'] = prev['AMT_CREDIT'] / prev['AMT_APPLICATION']\n",
    "    prev['PREV_ANNUITY_APPL_RATIO'] = prev['AMT_ANNUITY'] / prev['AMT_APPLICATION']\n",
    "    prev['PREV_GOODS_APPL_RATIO'] = prev['AMT_GOODS_PRICE'] / prev['AMT_APPLICATION']\n",
    "    \n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "    prev['PREV_DAYS_LAST_DUE_DIFF'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n",
    "    \n",
    "    all_pay = prev['AMT_ANNUITY'] * prev['CNT_PAYMENT']\n",
    "    prev['PREV_INTERESTS_RATE'] = (all_pay / prev['AMT_CREDIT'] - 1) / prev['CNT_PAYMENT']\n",
    "    \n",
    "    return prev\n",
    "\n",
    "\n",
    "def get_prev_amt_agg(prev):    \n",
    "\n",
    "    agg_dict = {\n",
    "         # 기존 컬럼. \n",
    "        'SK_ID_CURR':['count'],\n",
    "        'AMT_CREDIT':['mean', 'max', 'sum'],\n",
    "        'AMT_ANNUITY':['mean', 'max', 'sum'], \n",
    "        'AMT_APPLICATION':['mean', 'max', 'sum'],\n",
    "        'AMT_DOWN_PAYMENT':['mean', 'max', 'sum'],\n",
    "        'AMT_GOODS_PRICE':['mean', 'max', 'sum'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "        # 가공 컬럼\n",
    "        'PREV_CREDIT_DIFF':['mean', 'max', 'sum'], \n",
    "        'PREV_CREDIT_APPL_RATIO':['mean', 'max'],\n",
    "        'PREV_GOODS_DIFF':['mean', 'max', 'sum'],\n",
    "        'PREV_GOODS_APPL_RATIO':['mean', 'max'],\n",
    "        'PREV_DAYS_LAST_DUE_DIFF':['mean', 'max', 'sum'],\n",
    "        'PREV_INTERESTS_RATE':['mean', 'max']\n",
    "    }\n",
    "    \n",
    "    prev_group = prev.groupby('SK_ID_CURR')\n",
    "    prev_amt_agg = prev_group.agg(agg_dict)\n",
    "    prev_amt_agg.columns = ['PREV_' + ('_').join(column).upper() for column in prev_amt_agg.columns.ravel()]\n",
    "    prev_amt_agg = prev_amt_agg.reset_index()\n",
    "    \n",
    "    return prev_amt_agg\n",
    "\n",
    "\n",
    "def get_prev_refused_appr_agg(prev):\n",
    "\n",
    "    prev_refused_appr_group = prev[prev['NAME_CONTRACT_STATUS'].isin(['Approved', 'Refused'])].groupby(['SK_ID_CURR', 'NAME_CONTRACT_STATUS'])\n",
    "    prev_refused_appr_agg = prev_refused_appr_group['SK_ID_CURR'].count().unstack()\n",
    "    prev_refused_appr_agg = prev_refused_appr_agg.fillna(0)\n",
    "    prev_refused_appr_agg.columns = ['PREV_APPROVED_COUNT', 'PREV_REFUSED_COUNT']\n",
    "    prev_refused_appr_agg = prev_refused_appr_agg.reset_index()\n",
    "    \n",
    "    return prev_refused_appr_agg\n",
    "\n",
    "\n",
    "def get_prev_days365_agg(prev):\n",
    "    cond_days365 = prev['DAYS_DECISION'] > -365\n",
    "    prev_days365_group = prev[cond_days365].groupby('SK_ID_CURR')\n",
    "    agg_dict = {\n",
    "        'SK_ID_CURR':['count'],\n",
    "        'AMT_CREDIT':['mean', 'max', 'sum'],\n",
    "        'AMT_ANNUITY':['mean', 'max', 'sum'], \n",
    "        'AMT_APPLICATION':['mean', 'max', 'sum'],\n",
    "        'AMT_DOWN_PAYMENT':['mean', 'max', 'sum'],\n",
    "        'AMT_GOODS_PRICE':['mean', 'max', 'sum'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "\n",
    "        'PREV_CREDIT_DIFF':['mean', 'max', 'sum'], \n",
    "        'PREV_CREDIT_APPL_RATIO':['mean', 'max'],\n",
    "        'PREV_GOODS_DIFF':['mean', 'max', 'sum'],\n",
    "        'PREV_GOODS_APPL_RATIO':['mean', 'max'],\n",
    "        'PREV_DAYS_LAST_DUE_DIFF':['mean', 'max', 'sum'],\n",
    "        'PREV_INTERESTS_RATE':['mean', 'max']\n",
    "    }\n",
    "    \n",
    "    prev_days365_agg = prev_days365_group.agg(agg_dict)\n",
    "\n",
    "    prev_days365_agg.columns = [\"PREV_D365_\"+ \"_\".join(x).upper() for x in prev_days365_agg.columns.ravel()]\n",
    "    \n",
    "    return prev_days365_agg\n",
    "\n",
    "\n",
    "def get_prev_agg(prev):\n",
    "    \n",
    "    prev = get_prev_processed(prev)\n",
    "    prev_amt_agg = get_prev_amt_agg(prev)\n",
    "    prev_refused_appr_agg = get_prev_refused_appr_agg(prev)\n",
    "    prev_days365_agg = get_prev_days365_agg(prev) # get_prev_days365_agg\n",
    "    \n",
    "    prev_agg = prev_amt_agg.merge(prev_refused_appr_agg, on='SK_ID_CURR', how='left')\n",
    "    prev_agg = prev_agg.merge(prev_days365_agg, on='SK_ID_CURR', how='left') # leftjoin prev_days365_agg\n",
    "    prev_agg['PREV_REFUSED_RATIO'] = prev_agg['PREV_REFUSED_COUNT'] / prev_agg['PREV_SK_ID_CURR_COUNT']\n",
    "    prev_agg['PREV_APPROVED_RATIO'] = prev_agg['PREV_APPROVED_COUNT'] / prev_agg['PREV_SK_ID_CURR_COUNT']\n",
    "    prev_agg = prev_agg.drop(['PREV_REFUSED_COUNT', 'PREV_APPROVED_COUNT'], axis=1)\n",
    "    \n",
    "    return prev_agg\n",
    "\n",
    "\n",
    "def get_apps_all_with_prev_agg(apps, prev):\n",
    "\n",
    "    apps_all = get_apps_processed(apps)\n",
    "    prev_agg = get_prev_agg(prev)\n",
    "    print('prev_agg shape:', prev_agg.shape)\n",
    "    print('apps_all before merge shape:', apps_all.shape)\n",
    "    apps_all = apps_all.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
    "    print('apps_all after merge with prev_agg shape:', apps_all.shape)\n",
    "    \n",
    "    return apps_all\n",
    "\n",
    "\n",
    "def get_apps_all_encoded(apps_all):\n",
    "    \n",
    "    object_columns = apps_all.dtypes[apps_all.dtypes == 'object'].index.tolist()\n",
    "    for column in object_columns:\n",
    "        apps_all[column] = pd.factorize(apps_all[column])[0]\n",
    "    \n",
    "    return apps_all\n",
    "\n",
    "\n",
    "def get_apps_all_train_test(apps_all):\n",
    "\n",
    "    apps_all_train = apps_all[~apps_all['TARGET'].isnull()]\n",
    "    apps_all_test = apps_all[apps_all['TARGET'].isnull()]\n",
    "    apps_all_test = apps_all_test.drop('TARGET', axis=1)\n",
    "    \n",
    "    return apps_all_train, apps_all_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_agg_dict = {\n",
    "    'SK_ID_BUREAU': ['count'],\n",
    "    'DAYS_CREDIT': ['min', 'max', 'mean'],\n",
    "    'CREDIT_DAY_OVERDUE': ['min', 'max', 'mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "    'DAYS_ENDDATE_FACT': ['min', 'max', 'mean'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n",
    "    'AMT_ANNUITY': ['max', 'mean', 'sum'],\n",
    "\n",
    "    'BUREAU_ENDDATE_FACT_DIFF': ['min', 'max', 'mean'],\n",
    "    'BUREAU_CREDIT_FACT_DIFF': ['min', 'max', 'mean'],\n",
    "    'BUREAU_CREDIT_ENDDATE_DIFF': ['min', 'max', 'mean'],\n",
    "    'BUREAU_CREDIT_DEBT_RATIO': ['min', 'max', 'mean'],\n",
    "    'BUREAU_CREDIT_DEBT_DIFF': ['min', 'max', 'mean'],\n",
    "    'BUREAU_IS_DPD': ['mean', 'sum'],\n",
    "    'BUREAU_IS_DPD_OVER120': ['mean', 'sum'],\n",
    "}\n",
    "\n",
    "bureau_bal_agg_dict = {\n",
    "    'SK_ID_CURR': ['count'],\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'mean'],\n",
    "    'BUREAU_BAL_IS_DPD': ['mean', 'sum'],\n",
    "    'BUREAU_BAL_IS_DPD_OVER120': ['mean', 'sum'],\n",
    "}\n",
    "\n",
    "def get_bureau_processed(bureau):\n",
    "    \n",
    "    bureau['BUREAU_ENDDATE_FACT_DIFF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n",
    "    bureau['BUREAU_CREDIT_FACT_DIFF'] = bureau['DAYS_CREDIT'] - bureau['DAYS_ENDDATE_FACT']\n",
    "    bureau['BUREAU_CREDIT_ENDDATE_DIFF'] = bureau['DAYS_CREDIT'] - bureau['DAYS_CREDIT_ENDDATE']\n",
    "\n",
    "    bureau['BUREAU_CREDIT_DEBT_RATIO'] = bureau['AMT_CREDIT_SUM_DEBT'] / bureau['AMT_CREDIT_SUM']\n",
    "    bureau['BUREAU_CREDIT_DEBT_DIFF'] = bureau['AMT_CREDIT_SUM_DEBT'] - bureau['AMT_CREDIT_SUM']\\\n",
    "    \n",
    "    bureau['BUREAU_IS_DPD'] = bureau['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    bureau['BUREAU_IS_DPD_OVER120'] = bureau['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x > 120 else 0)\n",
    "    \n",
    "    return bureau\n",
    "\n",
    "\n",
    "def get_bureau_day_amt_agg(bureau):     \n",
    "\n",
    "    bureau_grp = bureau.groupby('SK_ID_CURR')\n",
    "    bureau_day_amt_agg = bureau_grp.agg(bureau_agg_dict)\n",
    "    bureau_day_amt_agg.columns = ['BUREAU_' + ('_').join(column).upper() for column in bureau_day_amt_agg.columns.ravel()]\n",
    "    bureau_day_amt_agg = bureau_day_amt_agg.reset_index()\n",
    "    \n",
    "    return bureau_day_amt_agg\n",
    "\n",
    "\n",
    "def get_bureau_active_agg(bureau):\n",
    "    \n",
    "    cond_active = bureau['CREDIT_ACTIVE'] == 'Active'\n",
    "    bureau_active_grp = bureau[cond_active].groupby('SK_ID_CURR')\n",
    "    bureau_active_agg = bureau_active_grp.agg(bureau_agg_dict)\n",
    "    bureau_active_agg.columns = ['BUREAU_ACT_' + ('_').join(column).upper() for column in bureau_active_agg.columns.ravel()]\n",
    "    bureau_active_agg = bureau_active_agg.reset_index()\n",
    "    \n",
    "    return bureau_active_agg\n",
    "\n",
    "\n",
    "def get_bureau_days750_agg(bureau):\n",
    "    cond_days750 = bureau['DAYS_CREDIT'] > -750\n",
    "    bureau_days750_group = bureau[cond_days750].groupby('SK_ID_CURR')\n",
    "    bureau_agg_dict = {\n",
    "        'SK_ID_BUREAU':['count'],\n",
    "        'DAYS_CREDIT':['min', 'max', 'mean'],\n",
    "        'CREDIT_DAY_OVERDUE':['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_ENDDATE':['min', 'max', 'mean'],\n",
    "        'DAYS_ENDDATE_FACT':['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean', 'sum'],\n",
    "\n",
    "        'BUREAU_ENDDATE_FACT_DIFF':['min', 'max', 'mean'],\n",
    "        'BUREAU_CREDIT_FACT_DIFF':['min', 'max', 'mean'],\n",
    "        'BUREAU_CREDIT_ENDDATE_DIFF':['min', 'max', 'mean'],\n",
    "        'BUREAU_CREDIT_DEBT_RATIO':['min', 'max', 'mean'],\n",
    "        'BUREAU_CREDIT_DEBT_DIFF':['min', 'max', 'mean'],\n",
    "        'BUREAU_IS_DPD':['mean', 'sum'],\n",
    "        'BUREAU_IS_DPD_OVER120':['mean', 'sum']\n",
    "        }\n",
    "\n",
    "    bureau_days750_agg = bureau_days750_group.agg(bureau_agg_dict)\n",
    "    bureau_days750_agg.columns = ['BUREAU_ACT_'+('_').join(column).upper() for column in bureau_days750_agg.columns.ravel()]\n",
    "    bureau_days750_agg = bureau_days750_agg.reset_index()\n",
    "    \n",
    "    return bureau_days750_agg\n",
    "\n",
    "\n",
    "def get_bureau_bal_agg(bureau, bureau_bal):\n",
    "    \n",
    "    bureau_bal = bureau_bal.merge(bureau[['SK_ID_CURR', 'SK_ID_BUREAU']], on='SK_ID_BUREAU', how='left')\n",
    "    bureau_bal['BUREAU_BAL_IS_DPD'] = bureau_bal['STATUS'].apply(lambda x: 1 if x in ['1', '2', '3', '4', '5'] else 0)\n",
    "    bureau_bal['BUREAU_BAL_IS_DPD_OVER120'] = bureau_bal['STATUS'].apply(lambda x: 1 if x == '5' else 0)\n",
    "    bureau_bal_grp = bureau_bal.groupby('SK_ID_CURR')\n",
    "    bureau_bal_agg = bureau_bal_grp.agg(bureau_bal_agg_dict)\n",
    "    bureau_bal_agg.columns = ['BUREAU_BAL_' + ('_').join(column).upper() for column in bureau_bal_agg.columns.ravel()]\n",
    "    bureau_bal_agg = bureau_bal_agg.reset_index()\n",
    "    \n",
    "    return bureau_bal_agg\n",
    "\n",
    "\n",
    "def get_bureau_agg(bureau, bureau_bal):\n",
    "    \n",
    "    bureau = get_bureau_processed(bureau)\n",
    "    bureau_day_amt_agg = get_bureau_day_amt_agg(bureau)\n",
    "    bureau_active_agg = get_bureau_active_agg(bureau)\n",
    "    bureau_days750_agg = get_bureau_days750_agg(bureau) # get_bureau_days750_agg\n",
    "    bureau_bal_agg = get_bureau_bal_agg(bureau, bureau_bal)\n",
    "    bureau_agg = bureau_day_amt_agg.merge(bureau_active_agg, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    bureau_agg['BUREAU_ACT_IS_DPD_RATIO'] = bureau_agg['BUREAU_ACT_BUREAU_IS_DPD_SUM'] / bureau_agg['BUREAU_SK_ID_BUREAU_COUNT']\n",
    "    bureau_agg['BUREAU_ACT_IS_DPD_OVER120_RATIO'] = bureau_agg['BUREAU_ACT_BUREAU_IS_DPD_OVER120_SUM'] / bureau_agg['BUREAU_SK_ID_BUREAU_COUNT']\n",
    "    \n",
    "    bureau_agg = bureau_agg.merge(bureau_bal_agg, on='SK_ID_CURR', how='left')\n",
    "    bureau_agg = bureau_agg.merge(bureau_days750_agg, on='SK_ID_CURR', how='left') # leftjoin bureau_days750_agg\n",
    "    print(f'bureau_agg shape: {bureau_agg.shape}')\n",
    "    \n",
    "    return bureau_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_bal_agg(pos_ball):\n",
    "    \n",
    "    pos_bal['POS_IS_DPD'] = pos_bal['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    pos_bal['POS_IS_DPD_UNDER_120'] = pos_bal['SK_DPD'].apply(lambda x: 1 if (x > 0) & (x < 120) else 0)\n",
    "    pos_bal['POS_IS_DPD_OVER_120'] = pos_bal['SK_DPD'].apply(lambda x: 1 if x >= 120 else 0)\n",
    "\n",
    "    pos_bal_grp = pos_bal.groupby('SK_ID_CURR')\n",
    "    pos_bal_agg_dict = {\n",
    "        'SK_ID_CURR': ['count'], \n",
    "        'MONTHS_BALANCE': ['min', 'mean', 'max'], \n",
    "        'SK_DPD': ['min', 'max', 'mean'],\n",
    "\n",
    "        'POS_IS_DPD': ['mean', 'sum'],\n",
    "        'POS_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'POS_IS_DPD_OVER_120': ['mean', 'sum'],\n",
    "    }\n",
    "\n",
    "    pos_bal_agg = pos_bal_grp.agg(pos_bal_agg_dict)\n",
    "    pos_bal_agg.columns = [('POS_') + ('_').join(column).upper() for column in pos_bal_agg.columns.ravel()]\n",
    "\n",
    "    cond_months = pos_bal['MONTHS_BALANCE'] > -20\n",
    "    pos_bal_m20_grp = pos_bal[cond_months].groupby('SK_ID_CURR')\n",
    "    pos_bal_agg_dict = {\n",
    "        'SK_ID_CURR': ['count'], \n",
    "        'MONTHS_BALANCE': ['min', 'mean', 'max'], \n",
    "        'SK_DPD': ['min', 'max', 'mean'],\n",
    "\n",
    "        'POS_IS_DPD': ['mean', 'sum'],\n",
    "        'POS_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'POS_IS_DPD_OVER_120': ['mean', 'sum'],\n",
    "    }\n",
    "\n",
    "    pos_bal_m20_agg = pos_bal_m20_grp.agg(pos_bal_agg_dict)\n",
    "    pos_bal_m20_agg.columns = [('POS_M20')+('_').join(column).upper() for column in pos_bal_m20_agg.columns.ravel()]\n",
    "\n",
    "    pos_bal_agg = pos_bal_agg.merge(pos_bal_m20_agg, on='SK_ID_CURR', how='left')\n",
    "    pos_bal_agg = pos_bal_agg.reset_index()\n",
    "    \n",
    "    return pos_bal_agg\n",
    "\n",
    "\n",
    "def get_install_agg(install):\n",
    "\n",
    "    install['AMT_DIFF'] = install['AMT_INSTALMENT'] - install['AMT_PAYMENT']\n",
    "    install['AMT_RATIO'] = (install['AMT_PAYMENT'] + 1) / (install['AMT_INSTALMENT'] + 1)\n",
    "\n",
    "    install['SK_DPD'] = install['DAYS_ENTRY_PAYMENT'] - install['DAYS_INSTALMENT']\n",
    "    \n",
    "    install['INS_IS_DPD'] = install['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    install['INS_IS_DPD_UNDER_120'] = install['SK_DPD'].apply(lambda x: 1 if (x > 0) & (x < 120) else 0)\n",
    "    install['INS_IS_DPD_OVER_120'] = install['SK_DPD'].apply(lambda x: 1 if x >= 120 else 0)\n",
    "\n",
    "    install_grp = install.groupby('SK_ID_CURR')\n",
    "    install_agg_dict = {\n",
    "        'SK_ID_CURR': ['count'],\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'], \n",
    "        'DAYS_ENTRY_PAYMENT': ['mean', 'max', 'sum'],\n",
    "        'DAYS_INSTALMENT': ['mean', 'max', 'sum'],\n",
    "        'AMT_INSTALMENT': ['mean', 'max', 'sum'],\n",
    "        'AMT_PAYMENT': ['mean', 'max','sum'],\n",
    "\n",
    "        'AMT_DIFF': ['mean','min', 'max','sum'],\n",
    "        'AMT_RATIO':[ 'mean', 'max'],\n",
    "        'SK_DPD': ['mean', 'min', 'max'],\n",
    "        'INS_IS_DPD': ['mean', 'sum'],\n",
    "        'INS_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'INS_IS_DPD_OVER_120': ['mean', 'sum'],\n",
    "    }\n",
    "\n",
    "    install_agg = install_grp.agg(install_agg_dict)\n",
    "    install_agg.columns = [('INS_') + ('_').join(column).upper() for column in install_agg.columns.ravel()]\n",
    "\n",
    "    cond_day = install['DAYS_ENTRY_PAYMENT'] >= -365\n",
    "    install_d365_grp = install[cond_day].groupby('SK_ID_CURR')\n",
    "    install_agg_dict = {\n",
    "        'SK_ID_CURR': ['count'],\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'], \n",
    "        'DAYS_ENTRY_PAYMENT': ['mean', 'max', 'sum'],\n",
    "        'DAYS_INSTALMENT': ['mean', 'max', 'sum'],\n",
    "        'AMT_INSTALMENT': ['mean', 'max', 'sum'],\n",
    "        'AMT_PAYMENT': ['mean', 'max','sum'],\n",
    "\n",
    "        'AMT_DIFF': ['mean','min', 'max','sum'],\n",
    "        'AMT_RATIO':[ 'mean', 'max'],\n",
    "        'SK_DPD': ['mean', 'min', 'max'],\n",
    "        'INS_IS_DPD': ['mean', 'sum'],\n",
    "        'INS_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'INS_IS_DPD_OVER_120': ['mean', 'sum'],\n",
    "    }\n",
    "\n",
    "    install_d365_agg = install_d365_grp.agg(install_agg_dict)\n",
    "    install_d365_agg.columns = [('INS_d365')+('_').join(column).upper() for column in install_d365_agg. columns.ravel()]\n",
    "\n",
    "    install_agg = install_agg.merge(install_d365_agg, on='SK_ID_CURR', how='left')\n",
    "    install_agg = install_agg.reset_index()\n",
    "    \n",
    "    return install_agg\n",
    "\n",
    "\n",
    "def get_card_bal_agg(card_bal):\n",
    "\n",
    "    card_bal['BALANCE_LIMIT_RATIO'] = card_bal['AMT_BALANCE'] / card_bal['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "    card_bal['DRAWING_LIMIT_RATIO'] = card_bal['AMT_DRAWINGS_CURRENT'] / card_bal['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "\n",
    "    card_bal['CARD_IS_DPD'] = card_bal['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    card_bal['CARD_IS_DPD_UNDER_120'] = card_bal['SK_DPD'].apply(lambda x: 1 if (x > 0) & (x < 120) else 0)\n",
    "    card_bal['CARD_IS_DPD_OVER_120'] = card_bal['SK_DPD'].apply(lambda x: 1 if x >= 120 else 0)\n",
    "\n",
    "    card_bal_grp = card_bal.groupby('SK_ID_CURR')\n",
    "    card_bal_agg_dict = {\n",
    "        'SK_ID_CURR': ['count'],\n",
    "        'AMT_BALANCE': ['max'],\n",
    "        'AMT_CREDIT_LIMIT_ACTUAL': ['max'],\n",
    "        'AMT_DRAWINGS_ATM_CURRENT': ['max', 'sum'],\n",
    "        'AMT_DRAWINGS_CURRENT': ['max', 'sum'],\n",
    "        'AMT_DRAWINGS_POS_CURRENT': ['max', 'sum'],\n",
    "        'AMT_INST_MIN_REGULARITY': ['max', 'mean'],\n",
    "        'AMT_PAYMENT_TOTAL_CURRENT': ['max','sum'],\n",
    "        'AMT_TOTAL_RECEIVABLE': ['max', 'mean'],\n",
    "        'CNT_DRAWINGS_ATM_CURRENT': ['max','sum'],\n",
    "        'CNT_DRAWINGS_CURRENT': ['max', 'mean', 'sum'],\n",
    "        'CNT_DRAWINGS_POS_CURRENT': ['mean'],\n",
    "        'SK_DPD': ['mean', 'max', 'sum'],\n",
    "\n",
    "        'BALANCE_LIMIT_RATIO': ['min','max'],\n",
    "        'DRAWING_LIMIT_RATIO': ['min', 'max'],\n",
    "        'CARD_IS_DPD': ['mean', 'sum'],\n",
    "        'CARD_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'CARD_IS_DPD_OVER_120': ['mean', 'sum'],\n",
    "    }\n",
    "\n",
    "    card_bal_agg = card_bal_grp.agg(card_bal_agg_dict)\n",
    "    card_bal_agg.columns = [('CARD_') + ('_').join(column).upper() for column in card_bal_agg.columns.ravel()]\n",
    "    \n",
    "    card_bal_agg = card_bal_agg.reset_index()\n",
    "\n",
    "    cond_month = card_bal['MONTHS_BALANCE'] >= -3\n",
    "    card_bal_m3_grp = card_bal[cond_month].groupby('SK_ID_CURR')\n",
    "\n",
    "    card_bal_m3_agg = card_bal_m3_grp.agg(card_bal_agg_dict)\n",
    "    card_bal_m3_agg.columns = ['CARD_M3'+('_').join(column).upper() for column in card_bal_m3_agg.  columns.ravel()]\n",
    "\n",
    "    card_bal_agg = card_bal_agg.merge(card_bal_m3_agg, on='SK_ID_CURR', how='left')\n",
    "    card_bal_agg = card_bal_agg.reset_index()\n",
    "    \n",
    "    return card_bal_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apps_all_with_all_agg(apps, prev, bureau, bureau_bal, pos_bal, install, card_bal):\n",
    "    \n",
    "    apps_all = get_apps_processed(apps)\n",
    "    prev_agg = get_prev_agg(prev)\n",
    "    bureau_agg = get_bureau_agg(bureau, bureau_bal)\n",
    "    pos_bal_agg = get_pos_bal_agg(pos_bal)\n",
    "    install_agg = get_install_agg(install)\n",
    "    card_bal_agg = get_card_bal_agg(card_bal)\n",
    "    \n",
    "    print(f'prev_agg shape: {prev_agg.shape}\\nbureau_agg shape: {bureau_agg.shape}')\n",
    "    print(f'pos_bal_agg shape: {pos_bal_agg.shape}\\ninstall_agg shape: {install_agg.shape}\\ncard_bal_agg shape: {card_bal_agg.shape}')\n",
    "    print(f'apps_all before merge shape: {apps_all.shape}')\n",
    "    \n",
    "    apps_all = apps_all.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
    "    apps_all = apps_all.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
    "    apps_all = apps_all.merge(pos_bal_agg, on='SK_ID_CURR', how='left')\n",
    "    apps_all = apps_all.merge(install_agg, on='SK_ID_CURR', how='left')\n",
    "    apps_all = apps_all.merge(card_bal_agg, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "    print(f'apps_all after merge with all shape: {apps_all.shape}')\n",
    "    \n",
    "    return apps_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bureau_agg shape: (305811, 149)\n",
      "prev_agg shape: (338857, 81)\n",
      "bureau_agg shape: (305811, 149)\n",
      "pos_bal_agg shape: (337252, 27)\n",
      "install_agg shape: (339587, 59)\n",
      "card_bal_agg shape: (103558, 70)\n",
      "apps_all before merge shape: (356255, 136)\n",
      "apps_all after merge with all shape: (356255, 517)\n"
     ]
    }
   ],
   "source": [
    "apps, prev, bureau, bureau_balance, pos_bal, install, card_bal = get_dataset()\n",
    "\n",
    "apps_all = get_apps_all_with_all_agg(apps, prev, bureau, bureau_balance, pos_bal, install, card_bal)\n",
    "apps_all = get_apps_all_encoded(apps_all)\n",
    "apps_all_train, apps_all_test = get_apps_all_train_test(apps_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train_apps_all_with_oof(apps_all_train, apps_all_test, nfolds=5):\n",
    "    ftr_app = apps_all_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
    "    target_app = apps_all_train['TARGET']\n",
    "    \n",
    "    folds = KFold(n_splits=nfolds, shuffle=True, random_state=0)\n",
    "    oof_preds = np.zeros(ftr_app.shape[0])\n",
    "    test_preds = np.zeros(apps_all_test.shape[0])\n",
    "    \n",
    "    clf = LGBMClassifier(\n",
    "        n_jobs=-1, \n",
    "        n_estimators=4000, \n",
    "        learning_rate=0.01,\n",
    "        # from hyper_parameter_tuning (BayesianOptimization)\n",
    "        colsample_bytree=0.601,\n",
    "        max_bin=348, \n",
    "        max_depth=12, \n",
    "        min_child_samples=107, \n",
    "        min_child_weight=8, \n",
    "        num_leaves=61, \n",
    "        reg_alpha=11.964, \n",
    "        reg_lambda=5.513, \n",
    "        subsample=0.773,\n",
    "        silent=-1, \n",
    "        verbose=-1,\n",
    "    )\n",
    "    \n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(folds.split(ftr_app)):\n",
    "        \n",
    "        print(f'##### iteration {fold_idx} start')\n",
    "        train_x = ftr_app.iloc[train_idx, :]\n",
    "        train_y = target_app.iloc[train_idx]\n",
    "        valid_x = ftr_app.iloc[valid_idx, :]\n",
    "        valid_y = target_app.iloc[valid_idx]\n",
    "        \n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "                eval_metric='auc', verbose=200, early_stopping_rounds=200)\n",
    "        test_preds += clf.predict_proba(\n",
    "            apps_all_test.drop('SK_ID_CURR', axis=1), num_iteration=clf.best_iteration_\n",
    "        )[:, 1] / folds.n_splits\n",
    "        \n",
    "    return clf, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### iteration 0 start\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.792083\ttraining's binary_logloss: 0.240864\tvalid_1's auc: 0.768996\tvalid_1's binary_logloss: 0.242225\n",
      "[400]\ttraining's auc: 0.812709\ttraining's binary_logloss: 0.230427\tvalid_1's auc: 0.78155\tvalid_1's binary_logloss: 0.236121\n",
      "[600]\ttraining's auc: 0.827139\ttraining's binary_logloss: 0.223902\tvalid_1's auc: 0.787922\tvalid_1's binary_logloss: 0.233518\n",
      "[800]\ttraining's auc: 0.839153\ttraining's binary_logloss: 0.218729\tvalid_1's auc: 0.791547\tvalid_1's binary_logloss: 0.232138\n",
      "[1000]\ttraining's auc: 0.849688\ttraining's binary_logloss: 0.21423\tvalid_1's auc: 0.79372\tvalid_1's binary_logloss: 0.231335\n",
      "[1200]\ttraining's auc: 0.85923\ttraining's binary_logloss: 0.210102\tvalid_1's auc: 0.795333\tvalid_1's binary_logloss: 0.230752\n",
      "[1400]\ttraining's auc: 0.867921\ttraining's binary_logloss: 0.206277\tvalid_1's auc: 0.796192\tvalid_1's binary_logloss: 0.230405\n",
      "[1600]\ttraining's auc: 0.875772\ttraining's binary_logloss: 0.202737\tvalid_1's auc: 0.796891\tvalid_1's binary_logloss: 0.230141\n",
      "[1800]\ttraining's auc: 0.883058\ttraining's binary_logloss: 0.199399\tvalid_1's auc: 0.797208\tvalid_1's binary_logloss: 0.230013\n",
      "[2000]\ttraining's auc: 0.889616\ttraining's binary_logloss: 0.196284\tvalid_1's auc: 0.797431\tvalid_1's binary_logloss: 0.22993\n",
      "[2200]\ttraining's auc: 0.895935\ttraining's binary_logloss: 0.193227\tvalid_1's auc: 0.797765\tvalid_1's binary_logloss: 0.229807\n",
      "[2400]\ttraining's auc: 0.9018\ttraining's binary_logloss: 0.19027\tvalid_1's auc: 0.79804\tvalid_1's binary_logloss: 0.229701\n",
      "[2600]\ttraining's auc: 0.907407\ttraining's binary_logloss: 0.187428\tvalid_1's auc: 0.798159\tvalid_1's binary_logloss: 0.229659\n",
      "[2800]\ttraining's auc: 0.912635\ttraining's binary_logloss: 0.184682\tvalid_1's auc: 0.798207\tvalid_1's binary_logloss: 0.229632\n",
      "[3000]\ttraining's auc: 0.91736\ttraining's binary_logloss: 0.182048\tvalid_1's auc: 0.798195\tvalid_1's binary_logloss: 0.229637\n",
      "Early stopping, best iteration is:\n",
      "[2806]\ttraining's auc: 0.912783\ttraining's binary_logloss: 0.184601\tvalid_1's auc: 0.798214\tvalid_1's binary_logloss: 0.229628\n",
      "##### iteration 1 start\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.792681\ttraining's binary_logloss: 0.239829\tvalid_1's auc: 0.769483\tvalid_1's binary_logloss: 0.246085\n",
      "[400]\ttraining's auc: 0.813403\ttraining's binary_logloss: 0.229231\tvalid_1's auc: 0.781784\tvalid_1's binary_logloss: 0.239927\n",
      "[600]\ttraining's auc: 0.827478\ttraining's binary_logloss: 0.222724\tvalid_1's auc: 0.78768\tvalid_1's binary_logloss: 0.23749\n",
      "[800]\ttraining's auc: 0.839281\ttraining's binary_logloss: 0.21759\tvalid_1's auc: 0.790906\tvalid_1's binary_logloss: 0.236269\n",
      "[1000]\ttraining's auc: 0.849841\ttraining's binary_logloss: 0.213071\tvalid_1's auc: 0.79286\tvalid_1's binary_logloss: 0.235576\n",
      "[1200]\ttraining's auc: 0.8595\ttraining's binary_logloss: 0.208921\tvalid_1's auc: 0.794155\tvalid_1's binary_logloss: 0.235129\n",
      "[1400]\ttraining's auc: 0.868178\ttraining's binary_logloss: 0.205092\tvalid_1's auc: 0.795276\tvalid_1's binary_logloss: 0.234762\n",
      "[1600]\ttraining's auc: 0.876084\ttraining's binary_logloss: 0.201534\tvalid_1's auc: 0.795884\tvalid_1's binary_logloss: 0.234536\n",
      "[1800]\ttraining's auc: 0.88324\ttraining's binary_logloss: 0.198199\tvalid_1's auc: 0.796147\tvalid_1's binary_logloss: 0.234443\n",
      "[2000]\ttraining's auc: 0.889972\ttraining's binary_logloss: 0.195024\tvalid_1's auc: 0.796428\tvalid_1's binary_logloss: 0.234353\n",
      "[2200]\ttraining's auc: 0.896277\ttraining's binary_logloss: 0.191975\tvalid_1's auc: 0.796537\tvalid_1's binary_logloss: 0.234325\n",
      "[2400]\ttraining's auc: 0.902076\ttraining's binary_logloss: 0.189049\tvalid_1's auc: 0.796585\tvalid_1's binary_logloss: 0.234302\n",
      "[2600]\ttraining's auc: 0.907664\ttraining's binary_logloss: 0.186209\tvalid_1's auc: 0.796711\tvalid_1's binary_logloss: 0.234271\n",
      "[2800]\ttraining's auc: 0.912835\ttraining's binary_logloss: 0.183482\tvalid_1's auc: 0.796807\tvalid_1's binary_logloss: 0.234258\n",
      "[3000]\ttraining's auc: 0.917676\ttraining's binary_logloss: 0.180833\tvalid_1's auc: 0.796863\tvalid_1's binary_logloss: 0.234253\n",
      "Early stopping, best iteration is:\n",
      "[2923]\ttraining's auc: 0.915821\ttraining's binary_logloss: 0.181838\tvalid_1's auc: 0.796885\tvalid_1's binary_logloss: 0.234241\n",
      "##### iteration 2 start\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.793404\ttraining's binary_logloss: 0.239662\tvalid_1's auc: 0.76731\tvalid_1's binary_logloss: 0.246613\n",
      "[400]\ttraining's auc: 0.814544\ttraining's binary_logloss: 0.229001\tvalid_1's auc: 0.778913\tvalid_1's binary_logloss: 0.24072\n",
      "[600]\ttraining's auc: 0.828745\ttraining's binary_logloss: 0.222475\tvalid_1's auc: 0.784182\tvalid_1's binary_logloss: 0.238451\n",
      "[800]\ttraining's auc: 0.840739\ttraining's binary_logloss: 0.217262\tvalid_1's auc: 0.787297\tvalid_1's binary_logloss: 0.237208\n",
      "[1000]\ttraining's auc: 0.851255\ttraining's binary_logloss: 0.212734\tvalid_1's auc: 0.788917\tvalid_1's binary_logloss: 0.236561\n",
      "[1200]\ttraining's auc: 0.860869\ttraining's binary_logloss: 0.208589\tvalid_1's auc: 0.789987\tvalid_1's binary_logloss: 0.236147\n",
      "[1400]\ttraining's auc: 0.869587\ttraining's binary_logloss: 0.204733\tvalid_1's auc: 0.790802\tvalid_1's binary_logloss: 0.23584\n",
      "[1600]\ttraining's auc: 0.877773\ttraining's binary_logloss: 0.201092\tvalid_1's auc: 0.791206\tvalid_1's binary_logloss: 0.235671\n",
      "[1800]\ttraining's auc: 0.885108\ttraining's binary_logloss: 0.197659\tvalid_1's auc: 0.791555\tvalid_1's binary_logloss: 0.235547\n",
      "[2000]\ttraining's auc: 0.891812\ttraining's binary_logloss: 0.194454\tvalid_1's auc: 0.791762\tvalid_1's binary_logloss: 0.235446\n",
      "[2200]\ttraining's auc: 0.898049\ttraining's binary_logloss: 0.191405\tvalid_1's auc: 0.791849\tvalid_1's binary_logloss: 0.235411\n",
      "[2400]\ttraining's auc: 0.903882\ttraining's binary_logloss: 0.188471\tvalid_1's auc: 0.791944\tvalid_1's binary_logloss: 0.23536\n",
      "[2600]\ttraining's auc: 0.909381\ttraining's binary_logloss: 0.185605\tvalid_1's auc: 0.791813\tvalid_1's binary_logloss: 0.235383\n",
      "Early stopping, best iteration is:\n",
      "[2400]\ttraining's auc: 0.903882\ttraining's binary_logloss: 0.188471\tvalid_1's auc: 0.791944\tvalid_1's binary_logloss: 0.23536\n",
      "##### iteration 3 start\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.792887\ttraining's binary_logloss: 0.239566\tvalid_1's auc: 0.768539\tvalid_1's binary_logloss: 0.247224\n",
      "[400]\ttraining's auc: 0.813872\ttraining's binary_logloss: 0.228965\tvalid_1's auc: 0.780029\tvalid_1's binary_logloss: 0.241279\n",
      "[600]\ttraining's auc: 0.828371\ttraining's binary_logloss: 0.222374\tvalid_1's auc: 0.7859\tvalid_1's binary_logloss: 0.238894\n",
      "[800]\ttraining's auc: 0.840303\ttraining's binary_logloss: 0.217197\tvalid_1's auc: 0.789008\tvalid_1's binary_logloss: 0.237737\n",
      "[1000]\ttraining's auc: 0.850871\ttraining's binary_logloss: 0.212663\tvalid_1's auc: 0.790938\tvalid_1's binary_logloss: 0.237044\n",
      "[1200]\ttraining's auc: 0.860438\ttraining's binary_logloss: 0.208531\tvalid_1's auc: 0.79219\tvalid_1's binary_logloss: 0.236603\n",
      "[1400]\ttraining's auc: 0.869078\ttraining's binary_logloss: 0.204718\tvalid_1's auc: 0.793048\tvalid_1's binary_logloss: 0.2363\n",
      "[1600]\ttraining's auc: 0.876947\ttraining's binary_logloss: 0.201144\tvalid_1's auc: 0.793732\tvalid_1's binary_logloss: 0.236051\n",
      "[1800]\ttraining's auc: 0.884188\ttraining's binary_logloss: 0.197786\tvalid_1's auc: 0.794046\tvalid_1's binary_logloss: 0.235941\n",
      "[2000]\ttraining's auc: 0.890927\ttraining's binary_logloss: 0.194587\tvalid_1's auc: 0.794328\tvalid_1's binary_logloss: 0.235838\n",
      "[2200]\ttraining's auc: 0.89715\ttraining's binary_logloss: 0.191564\tvalid_1's auc: 0.794579\tvalid_1's binary_logloss: 0.235765\n",
      "[2400]\ttraining's auc: 0.903016\ttraining's binary_logloss: 0.188642\tvalid_1's auc: 0.79474\tvalid_1's binary_logloss: 0.23573\n",
      "[2600]\ttraining's auc: 0.908511\ttraining's binary_logloss: 0.185799\tvalid_1's auc: 0.794872\tvalid_1's binary_logloss: 0.235696\n",
      "[2800]\ttraining's auc: 0.913724\ttraining's binary_logloss: 0.183051\tvalid_1's auc: 0.794966\tvalid_1's binary_logloss: 0.235683\n",
      "Early stopping, best iteration is:\n",
      "[2752]\ttraining's auc: 0.912504\ttraining's binary_logloss: 0.183711\tvalid_1's auc: 0.795023\tvalid_1's binary_logloss: 0.235659\n",
      "##### iteration 4 start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.793069\ttraining's binary_logloss: 0.239311\tvalid_1's auc: 0.768941\tvalid_1's binary_logloss: 0.24806\n",
      "[400]\ttraining's auc: 0.814009\ttraining's binary_logloss: 0.228729\tvalid_1's auc: 0.780071\tvalid_1's binary_logloss: 0.242189\n",
      "[600]\ttraining's auc: 0.82844\ttraining's binary_logloss: 0.222156\tvalid_1's auc: 0.785464\tvalid_1's binary_logloss: 0.239894\n",
      "[800]\ttraining's auc: 0.840247\ttraining's binary_logloss: 0.21702\tvalid_1's auc: 0.78854\tvalid_1's binary_logloss: 0.238708\n",
      "[1000]\ttraining's auc: 0.850782\ttraining's binary_logloss: 0.212509\tvalid_1's auc: 0.790496\tvalid_1's binary_logloss: 0.23801\n",
      "[1200]\ttraining's auc: 0.860385\ttraining's binary_logloss: 0.208387\tvalid_1's auc: 0.791839\tvalid_1's binary_logloss: 0.237538\n",
      "[1400]\ttraining's auc: 0.869223\ttraining's binary_logloss: 0.204509\tvalid_1's auc: 0.792669\tvalid_1's binary_logloss: 0.237263\n",
      "[1600]\ttraining's auc: 0.877168\ttraining's binary_logloss: 0.20094\tvalid_1's auc: 0.793256\tvalid_1's binary_logloss: 0.237061\n",
      "[1800]\ttraining's auc: 0.884367\ttraining's binary_logloss: 0.197583\tvalid_1's auc: 0.79364\tvalid_1's binary_logloss: 0.23693\n",
      "[2000]\ttraining's auc: 0.891006\ttraining's binary_logloss: 0.194411\tvalid_1's auc: 0.793873\tvalid_1's binary_logloss: 0.236858\n",
      "[2200]\ttraining's auc: 0.897426\ttraining's binary_logloss: 0.19134\tvalid_1's auc: 0.794032\tvalid_1's binary_logloss: 0.23681\n",
      "[2400]\ttraining's auc: 0.903343\ttraining's binary_logloss: 0.188387\tvalid_1's auc: 0.794163\tvalid_1's binary_logloss: 0.236774\n",
      "[2600]\ttraining's auc: 0.90877\ttraining's binary_logloss: 0.185565\tvalid_1's auc: 0.794244\tvalid_1's binary_logloss: 0.236768\n",
      "Early stopping, best iteration is:\n",
      "[2473]\ttraining's auc: 0.905354\ttraining's binary_logloss: 0.187346\tvalid_1's auc: 0.794258\tvalid_1's binary_logloss: 0.236756\n"
     ]
    }
   ],
   "source": [
    "clf, test_preds = train_apps_all_with_oof(apps_all_train, apps_all_test, nfolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_all_test['TARGET'] = test_preds\n",
    "apps_all_test[['SK_ID_CURR', 'TARGET']].to_csv('../result/out_of_prediction_result_02.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
